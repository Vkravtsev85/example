{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b525a08a",
   "metadata": {},
   "source": [
    "# Практическая работа (Прореживание/pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa35ba",
   "metadata": {},
   "source": [
    "# Задача: Реализовать стратегию \"Итеративное прореживание\" для задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ff839",
   "metadata": {},
   "source": [
    "В данной работе необходимо реализовать **прореживание** ранее обученной сети (```pruning```) модели. Для этого нам потребуется библиотека NNI, в которой реализован автоматический pruning: https://nni.readthedocs.io/en/stable/Compression/Overview.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2e618",
   "metadata": {},
   "source": [
    "Прореживание нейронной сети основана на той идеи, что в сети много излишних нейронов, которые мало влияют на конечный выход сети. Отсюда возникает идея - взять хорошо обученную модель и устранить в ней как можно больше весов и операций, при этом не потеряв существенно в качестве. Более того, при небольшом прореживании обычно наблюдается повышение качества на тестовой выборке. Предположительно, ликвидация лишних параметров убирает \"шумные веса\" из модели и разрушает случайные закономерности, которые сеть обнаруживает на обучающей выборке, но не являющиеся характерным для всего распределения данных в целом. \n",
    "\n",
    "На практике сверточные сети можно прорядить от 60-95% потеряв в точности менее 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d0e4f",
   "metadata": {},
   "source": [
    "***Поиск удаляемых сверток***\n",
    "\n",
    "Есть несколько вариантов выбора сверток для удаления:\n",
    "\n",
    "\n",
    " - Наименьшая ```L1-мера``` или low_magnitude_pruning. Идея, говорящая о том, что свертки с малыми значениями весов, вносят малый вклад в итоговое принятие решения\n",
    " - Наименьшая L1-мера с учетом среднего и стандартного отклонения. Дополняем оценкой характера распределения.\n",
    " - Маскирование сверток и исключение наименее влияющих на итоговую точность. Более точное определение малозначимых свёрток, но весьма затратное по времени и ресурсам.\n",
    " - Прочие\n",
    "\n",
    "Какой метод лучше \"сработает\" зависит от конкретной задачи и выбранной архитектуры сети. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec6bdf",
   "metadata": {},
   "source": [
    "**Существует несколько стратегий по прореживанию моделей:**\n",
    "\n",
    " - Однократное прореживание (**One-shot pruning**).\n",
    "\n",
    "    Берется предварительно обученная модель и в определенный момент устраняется некоторая часть весов согласно алгоритму прореживания. Можно на этом этапе оставить все как есть, но обыкновенно продолжают обучение на протяжении еще некоторого количества эпох, тем более, что при использовании более грубых методов, вроде magnitude-based, качество первоначально может заметно просесть и восстановиться до уровня близкого в исходной модели, только после оптимизации. При этом важно дождаться сходимости к оптимуму, так как если проредить еще не оптимальную модель, итоговое качество будет несколько хуже.\n",
    "    \n",
    "\n",
    " - Итеративное прореживание\n",
    "\n",
    "    Модель прореживается постепенно. Через число шагов, определенных расписанием прореживания (```pruning schedule```), часть весов устраняется из модели, затем проводится дообучение модели. Данная процедура проводится некоторое количество раз до тех пор пока модель не достигнет требуемой разреженности. Здесь, как можно заметить, довольно большой простор для подбора гиперпараметров - сколько весов отбросить на данной итерации, сколько эпох обучать модель между каждой итерацией.\n",
    "    \n",
    "\n",
    " - Обучение разреженной модели c самого начала\n",
    "\n",
    "    Кроме того, можно стартовать сразу с разреженной модели, а затем уже по ходу дела убирать наименее важные веса и заодно наращивать новые веса (которые до этого были обращены в нуль) на основе некоторого критерия. Достоинством данного подхода является возможность обучения моделей, которые в плотном виде (dense) не помещаются в память устройства.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac660f5",
   "metadata": {},
   "source": [
    "В данной работе продемонстрирую первую стратегию - Однократное прореживание, а вторую стратегию \"Итеративное прореживание\" нужно будет реализовать самостоятельно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55b252",
   "metadata": {},
   "source": [
    "### 1.1 Установка библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c1733",
   "metadata": {},
   "source": [
    "Для начала поставим нужные библиотеки с помощью терминальной команды pip. Терминальные команды можно использовать в Jupyter Notebook-ах и Colab-е. Для того, чтобы запустить терминальную команду, необходимо перед командой поставить восклицательный знак. Например, чтобы посмотреть содержимое папки, можно использовать команду ```!ls```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e218116",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torchvision tqdm nni -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7432c4",
   "metadata": {},
   "source": [
    "### 1.2 Импортирование модулей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a084705",
   "metadata": {},
   "source": [
    "В этом практическом задании мы будем использовать несколько библиотек. Во-первых, это ```Pytorch``` и ```torchvision```. Кроме этого, нам понадобится ```NNI``` : при помощи него мы будем прореживать конвалюционные слои нейронные сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b092b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                       \n",
    "import torch                       \n",
    "import torchvision                       \n",
    "from torch import nn                       \n",
    "from torch.autograd import Variable                       \n",
    "from torchvision.datasets import MNIST \n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T                      \n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from nni.algorithms.compression.pytorch.pruning import L1FilterPruner\n",
    "from nni.algorithms.compression.pytorch.pruning import L2FilterPruner\n",
    "from nni.compression.pytorch import ModelSpeedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffda36",
   "metadata": {},
   "source": [
    "### 1.3 Воспроизводимое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7679ece",
   "metadata": {},
   "source": [
    "Для того, чтобы постепенно улучшать процесс обучения нейронной сети, необходимо позаботиться о том, чтобы результат обучения воспроизводился от запуска к запуску. Поскольку при обучении нейронных сетей часто используются псевдослучайные числа, необходимо, чтобы генераторы случайных чисел выдавали одни и те же последовательности от запуска к запуску. Кроме того, необходимо переключить CUDA в детерминированный режим. Это требование уменьшает скорость выполнения программы, зато результаты вычислений становятся воспроизводимыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0729ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f201e",
   "metadata": {},
   "source": [
    "### 2.1 Определим функции для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129c58c",
   "metadata": {},
   "source": [
    "Класс ```MetricMonitor``` вспомогательный, который агригирует значения по каждому новому batch и выводит статистику онлайн накопительным образом. Это позволяет во время обучения мониторить изменение метрик.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2727e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b956dd77",
   "metadata": {},
   "source": [
    "Функция ```train``` отвечает за обучение. При этом, функция универсальная, тк работает с входными переменными: датасет ```train_loader```, модель ```model```, функцию ошибок ```criterion```, функцию оптимизации ```optimizer```, число эпох для обучения ```epochs``` и ```params```\n",
    "\n",
    "Внутри функции мы бежим по всему нашему тренировочному датасету и пропускаем его через модель для определения градиентов ошибки по bath (```criterian```). Внутри цикла происходит обновление весов на основе ```backward```. Предсказание модели получаем с помощью функции argmax по последнему слою, а показатели ```Loss``` и ```Accuracy``` помещаем в класс ```MetricMonitor```. \n",
    "Библиотека ```tqdm``` помогает визуализировать бегунок прогресса и значения, которые передаются в класс ```MetricMonitor```\n",
    "\n",
    "Функция ```validate```  отчечает за прогон данных на валидационной выборке ```val_loader``` и так же универсальна, тк большую часть переменных получает извне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32294da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epochs, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    eterator = tqdm(train_loader)\n",
    "    for i, data in enumerate(eterator, start=1):\n",
    "        \n",
    "        image, label = data\n",
    "        image = image.to(params[\"device\"], non_blocking=True)\n",
    "        label = label.to(params[\"device\"], non_blocking=True)\n",
    "        output = model(image)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        loss = criterion(output, label)\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", pred.eq(label.view_as(pred)).sum().item()/pred.shape[0]) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        eterator.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epochs, metric_monitor=metric_monitor)\n",
    "        )\n",
    "        \n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    eterator = tqdm(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(eterator, start=1):\n",
    "            image = image.to(params[\"device\"], non_blocking=True)\n",
    "            label = label.to(params[\"device\"], non_blocking=True)\n",
    "            output = model(image)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            loss = criterion(output, label)\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", pred.eq(label.view_as(pred)).sum().item()/pred.shape[0])\n",
    "            eterator.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )\n",
    "            \n",
    "    return metric_monitor\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c561e",
   "metadata": {},
   "source": [
    "### 2.2 Определим функцию паплайна(```pipeline```) для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aece8a7",
   "metadata": {},
   "source": [
    "Функция ```train_and_validate``` инициализирует train и valid датасет, задает функцию потерь (```CrossEntropyLoss```) и фунцию оптимизации ```AdamW```, затем последовательно в Эпохе вызывает ранее определенную функцию обучения и функцию валидации.\n",
    "Обращаю внимание, что этот паплайн возвращает в качестве результата обученную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07696566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_dataset, val_dataset, params):    \n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=params[\"batch_size\"],\n",
    "                              num_workers=params[\"num_workers\"],\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True,\n",
    "                              drop_last = True)\n",
    "    \n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                              batch_size=params[\"batch_size\"],\n",
    "                              num_workers=params[\"num_workers\"],\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True)\n",
    "    best_metric = 1000\n",
    "    \n",
    "    criterion =  nn.CrossEntropyLoss().to(params[\"device\"])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=params[\"lr\"])\n",
    "    \n",
    "    for epoch in range(1, params[\"epochs\"] + 1):\n",
    "        train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "        metric_monitor_ = validate(val_loader, model, criterion, epoch, params)\n",
    "        \n",
    "        metric = metric_monitor_.metrics['Accuracy']['avg']\n",
    "\n",
    "        if best_metric > metric:\n",
    "            best_metric = metric\n",
    "            torch.save(model.state_dict(), \"./best_model.pth\")\n",
    "            \n",
    "    torch.save(model.state_dict(), \"./final_model.pth\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed196e",
   "metadata": {},
   "source": [
    "### 3.1 Инициализация датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7584c",
   "metadata": {},
   "source": [
    "В этом ноутбуке мы не будем писать своих датасетов, а будем использовать те, что имеются в наличии во вспомогательной библиотеке `torchvision`. Нас будет интересовать датасет `Cifar10` (10 классов).\n",
    "\n",
    "1. Изучите интерфейс класса `torchvision.datasets.CIFAR10`. Посмотрите, какими параметрами можно влиять на этот датасет.\n",
    "\n",
    "2. Инициализируйте тренировочный и тестовый датасеты (`torchvision.datasets.CIFAR10`). \n",
    "\n",
    "3. В конструкторе используйте следующие параметры:\n",
    "    * аугментации из `torchvision.transforms`:\n",
    "        * `T.ToTensor()`\n",
    "        * `T.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),`\n",
    "\n",
    "    * `root` -- любой на Ваш вкус\n",
    "    * проанализируйте и выставьте остальные аргументы так, как вам кажется правильнее. Не забывайте, что перемешивать датасет имеет смысл для тренировочной выборки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b2d124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Cifar/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b53d21e6b58463e85d8046240510952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Cifar/cifar-10-python.tar.gz to ./Cifar\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "preprocess = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "data_train = CIFAR10(root=\"./Cifar\",train = True, transform = preprocess, download=True)\n",
    "data_test = CIFAR10(root=\"./Cifar\",train = False, transform = preprocess, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf941b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x135ac6ca0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_train.data[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7cdc52",
   "metadata": {},
   "source": [
    "### 4.1 Проведем файн-тюнинг модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6692715b",
   "metadata": {},
   "source": [
    "Для файн-тюнинга модели будем использорвать предобученную модель ResNet18 из библиотеки ```torchvision```. В оригинале модель обучена на датасете Imagenet, где предсказанием является один из 1000 классов. В нашем случае ответ модели другой, поэтому заменим последний линейный слой ```fc``` на слой с 10 нейронами, что соответствует количеству классов в нашем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b39c998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/kravtsev-vs/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d35a4a813174059ae226c99686e992c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18( pretrained= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa2a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained= True)\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "model = model.to(params[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f3c7f",
   "metadata": {},
   "source": [
    "Зададим прочие параметры обучения в объект типа dict ```params```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f53207",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"device\": \"cpu\",\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_workers\": 8,\n",
    "    \"epochs\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4ee3b",
   "metadata": {},
   "source": [
    "И запустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aefd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_and_validate(model, data_train, data_test, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12359b",
   "metadata": {},
   "source": [
    "### 5.1 Оптимизация(прунинг) ранее обученно модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d7f7d",
   "metadata": {},
   "source": [
    "Проведем оптимизацию моделей двумя разными методами для сравнения ```L1FilterPruner``` (https://arxiv.org/pdf/1608.08710.pdf) и ```L2FilterPruner```. Подробнее о методах можно узнать в оригинальных статьях, ниже освежим в памяти алгоритм для L1Filter Pruner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725e0bc",
   "metadata": {},
   "source": [
    "\n",
    "L1Filter Pruner удаляет фильтры в сверточных слоях\n",
    "\n",
    "Процедура обрезки m фильтров из i-го сверточного слоя выглядит следующим образом:\n",
    "\n",
    "Для каждого фильтра http://latex.codecogs.com/gif.latex?F_%7Bi,j%7Dвычислите сумму его абсолютных весов ядраhttp://latex.codecogs.com/gif.latex?s_j=%5Csum_%7Bl=1%7D%5E%7Bn_i%7D%5Csum%7CK_l%7C\n",
    "Отсортируйте фильтры по http://latex.codecogs.com/gif.latex?s_j.\n",
    "Сократите http://latex.codecogs.com/gif.latex?mфильтры с наименьшими значениями суммы и их соответствующими картами признаков. Ядра в следующем сверточном слое, соответствующем сокращенным картам объектов, также удаляются.\n",
    "Новая матрица ядра создается как для слоя th, так http://latex.codecogs.com/gif.latex?iи http://latex.codecogs.com/gif.latex?i+1для слоя th, а оставшиеся веса ядра копируются в новую модель.\n",
    "\n",
    "сохраним результаты прореженных моделей \"model_prunel1.pth\" и \"model_prunel2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb898d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задаем конфигурацию прореживания - Conv2d стой и sparsity 0,5 (или сремимся убрать 50% фильтров)\n",
    "config_list = [{ 'sparsity': 0.5, 'op_types': ['Conv2d'] }]\n",
    "\n",
    "#Загружаем лучшую модель\n",
    "model = torchvision.models.resnet18( pretrained= False)\n",
    "model_w = torch.load (\"./best_model.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(model_w).eval()\n",
    "\n",
    "#Создаем тензор для поиска кандидатов на прореживания\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(\"cpu\")\n",
    "\n",
    "\n",
    "#Запускаем алгоритм поиска кандидатов на прореживания, в результате сохраним веса новой модеои и маску прореженного графа сети\n",
    "pruner = L1FilterPruner(model, config_list);\n",
    "pruned_model = pruner.compress();\n",
    "pruner.export_model(model_path='./test.pt', mask_path='./test_mask.pt')\n",
    "\n",
    "#Применим новые веса для ускорения модели, для чего заново загрузим модель и в соответствии с маской удалим ненужные веса \n",
    "model_new = torchvision.models.resnet18( pretrained= False)\n",
    "model_w = torch.load (\"./best_model.pth\", map_location=\"cpu\")\n",
    "model_new.load_state_dict(model_w).eval()\n",
    "m_speedup = ModelSpeedup(model_new, dummy_input, './test_mask.pt')\n",
    "m_speedup.speedup_model();\n",
    "\n",
    "\n",
    "torch.save(m, \"./model_prunel1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2ca72",
   "metadata": {},
   "source": [
    "Проведем ту же операцию с L2Filter Pruner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c35ce81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-08 19:11:54] INFO (nni.compression.pytorch.compressor/MainThread) Model state_dict saved to ./test.pt\n",
      "[2022-04-08 19:11:54] INFO (nni.compression.pytorch.compressor/MainThread) Mask dict saved to ./test_mask.pt\n",
      "[2022-04-08 19:11:55] INFO (nni.compression.pytorch.speedup.compressor/MainThread) start to speed up the model\n",
      "[2022-04-08 19:11:55] INFO (FixMaskConflict/MainThread) {'conv1': 1, 'layer1.0.conv1': 1, 'layer1.0.conv2': 1, 'layer1.1.conv1': 1, 'layer1.1.conv2': 1, 'layer2.0.conv1': 1, 'layer2.0.conv2': 1, 'layer2.0.downsample.0': 1, 'layer2.1.conv1': 1, 'layer2.1.conv2': 1, 'layer3.0.conv1': 1, 'layer3.0.conv2': 1, 'layer3.0.downsample.0': 1, 'layer3.1.conv1': 1, 'layer3.1.conv2': 1, 'layer4.0.conv1': 1, 'layer4.0.conv2': 1, 'layer4.0.downsample.0': 1, 'layer4.1.conv1': 1, 'layer4.1.conv2': 1}\n",
      "[2022-04-08 19:11:55] INFO (FixMaskConflict/MainThread) dim0 sparsity: 0.500000\n",
      "[2022-04-08 19:11:55] INFO (FixMaskConflict/MainThread) dim1 sparsity: 0.000000\n",
      "[2022-04-08 19:11:55] INFO (FixMaskConflict/MainThread) Dectected conv prune dim\" 0\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) infer module masks...\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for maxpool\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.aten::add_.61\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.aten::add_.62\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer1.1.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.downsample.0\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.downsample.1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.aten::add_.63\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.aten::add_.64\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer2.1.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.downsample.0\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.downsample.1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.aten::add_.65\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.aten::add_.66\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer3.1.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.downsample.0\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.downsample.1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.aten::add_.67\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.0.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.conv1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.bn1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.conv2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.aten::add_.68\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for layer4.1.relu\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for avgpool\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for .aten::flatten.60\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update mask for fc\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the fc\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the .aten::flatten.60\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the avgpool\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.relu.1\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.aten::add_.68\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.bn2\n",
      "[2022-04-08 19:11:56] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.conv2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.1.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.relu.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.aten::add_.67\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.bn2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.downsample.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.conv2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.downsample.0\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer4.0.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.relu.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.aten::add_.66\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.bn2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.conv2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.1.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.relu.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.aten::add_.65\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.bn2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.downsample.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.conv2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.downsample.0\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer3.0.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.relu.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.aten::add_.64\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.bn2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.conv2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.1.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.relu.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.aten::add_.63\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.bn2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.downsample.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.conv2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.downsample.0\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer2.0.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.relu.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.aten::add_.62\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.bn2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.conv2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.1.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.relu.1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.aten::add_.61\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.bn2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.conv2\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the layer1.0.conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the maxpool\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the relu\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the bn1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Update the indirect sparsity for the conv1\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) resolve the mask conflict\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace compressed modules...\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 53\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: maxpool, op_type: MaxPool2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 32\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 53\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer1.0.aten::add_.61, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 32\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 53\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer1.1.aten::add_.62, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer1.1.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.downsample.0, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 64\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.downsample.1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 122\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 122\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer2.0.aten::add_.63, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 64\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 122\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer2.1.aten::add_.64, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer2.1.relu, op_type: ReLU)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.downsample.0, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 128\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.downsample.1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 239\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 239\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer3.0.aten::add_.65, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 128\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 239\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer3.1.aten::add_.66, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer3.1.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.downsample.0, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 256\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.downsample.1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 463\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 463\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer4.0.aten::add_.67, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.0.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.conv1, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.bn1, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 256\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.conv2, op_type: Conv2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.bn2, op_type: BatchNorm2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace batchnorm2d with num_features: 463\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: layer4.1.aten::add_.68, op_type: aten::add_) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: layer4.1.relu, op_type: ReLU)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: avgpool, op_type: AdaptiveAvgPool2d)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) Warning: cannot replace (name: .aten::flatten.60, op_type: aten::flatten) which is func type\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) replace module (name: fc, op_type: Linear)\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compress_modules/MainThread) replace linear with new in_features: 463, out_features: 10\n",
      "[2022-04-08 19:11:57] INFO (nni.compression.pytorch.speedup.compressor/MainThread) speedup done\n"
     ]
    }
   ],
   "source": [
    "config_list = [{ 'sparsity': 0.5, 'op_types': ['Conv2d'] }]\n",
    "\n",
    "model = torchvision.models.resnet18( pretrained= False)\n",
    "model_w = torch.load (\"./best_model.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(model_w).eval()\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(\"cpu\")\n",
    "\n",
    "pruner = L2FilterPruner(model, config_list) \n",
    "pruned_model = pruner.compress();\n",
    "pruner.export_model(model_path='./test.pt', mask_path='./test_mask.pt')\n",
    "\n",
    "model_new = torchvision.models.resnet18( pretrained= False)\n",
    "model_w = torch.load (\"./best_model.pth\", map_location=\"cpu\")\n",
    "model_new.load_state_dict(model_w).eval()\n",
    "m_speedup = ModelSpeedup(model_new, dummy_input, './test_mask.pt')\n",
    "m_speedup.speedup_model();\n",
    "\n",
    "torch.save(m, \"./model_prunel2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad6e5d",
   "metadata": {},
   "source": [
    "### 5.2 Анализ результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485061c",
   "metadata": {},
   "source": [
    "Проведем анализ получившихся результатов по рамеру моделей и  скорости работы. Для этого создадим функцию оценки количества весов модели\n",
    "```get_n_params```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc77535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "805dd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prunel1 = torch.load (\"./model_prunel1.pth\", map_location=\"cpu\").eval()\n",
    "model_prunel2 = torch.load (\"./model_prunel2.pth\", map_location=\"cpu\").eval()\n",
    "\n",
    "model = torchvision.models.resnet18( pretrained= False)\n",
    "model_w = torch.load (\"./best_model.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(model_w).eval()\n",
    "\n",
    "dummy_input = torch.ones(128, 3, 32, 32).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbf9d259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5159194"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model_prunel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e356554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1pruning 46.14%, L2pruning 46.38% parametr of original\n"
     ]
    }
   ],
   "source": [
    "print (\"L1pruning {metric1}%, L2pruning {metric2}% parametr of original\".format( \\\n",
    "                                    metric1=round(get_n_params(model_prunel1)/get_n_params(model)*100,2), \\\n",
    "                                    metric2=round(get_n_params(model_prunel2)/get_n_params(model)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c539425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 ms ± 9.63 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54515018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 ms ± 916 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_prunel1(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22ce5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 240 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model_prunel2(dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993997c",
   "metadata": {},
   "source": [
    "### 5.3 Дообучение пруниных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98d1c5",
   "metadata": {},
   "source": [
    "После прунинга точность моделей заметно уменьшается, поэтому требуется дообучение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8e118ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"device\": \"cpu\",\n",
    "    \"lr\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_workers\": 8,\n",
    "    \"epochs\": 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prunel1 = train_and_validate(model_prunel1.to(\"cpu\"), data_train, data_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prunel2 = train_and_validate(model_prunel2.to(\"cuda\"), data_train, data_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e111b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b043e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
